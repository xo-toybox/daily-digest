{
  "url": "https://langfuse.com/docs/observability/overview",
  "type": "webpage",
  "content": "LLM Observability & Application Tracing (open source) - Langfuse \n \n \n \n \n \n \n \n \n \n \n \n \n \n Docs \n Integrations Self Hosting Guides AI Engineering Library \n \n Overview \n Example Project \n Ask AI \n Get Started \n Start Tracing \n Use Prompt Management \n Set up Evals \n Products \n Observability Overview \n Get Started \n Concepts \n Features Essential \n Sessions \n User Tracking \n Environments \n Tags \n Metadata \n Trace IDs & Distributed Tracing \n Advanced \n User Feedback \n Log Levels \n Agent Graphs \n Comments \n Masking \n MCP Tracing \n Multi-Modality \n Observation Types \n Event queuing/batching \n Releases & Versioning \n Sampling \n Token & Cost Tracking \n Trace URLs \n Query Data \u2197 \n Metrics API \u2197 \n Custom Dashboards \u2197 \n \n \n \n SDKs Overview \n Instrumentation \n Advanced Features \n Troubleshooting & FAQ \n Upgrade Path \n Python Reference \u2197 \n JS/TS Reference \u2197 \n \n \n \n Integrations \u2197 \n Troubleshooting & FAQ \n \n \n \n Prompt Management Overview \n Get Started \n Concepts \n Features Essential \n Link to Traces \n Version Control \n Playground \n Advanced \n Variables \n Prompt Composability \n Message Placeholders \n Config \n Prompt Experiments \u2197 \n Caching \n MCP Server \n Webhooks \n GitHub Integration \n n8n Node \n Guaranteed Availability \n A/B Testing \n Folders \n \n \n \n Troubleshooting & FAQ \n \n \n \n Evaluation Overview \n Concepts \n Evaluation Methods Overview \n LLM-as-a-Judge \n Annotation Queues \n Scores via UI \n Scores via API/SDK \n Score Analytics \n \n \n \n Experiments Overview \n Datasets \n Experiments via SDK \n Experiments via UI \n Data Model \n \n \n \n Guides \u2197 \n Troubleshooting & FAQ \n \n \n \n Platform \n Metrics Overview \n Features Custom Dashboards \n Metrics API \n Export to PostHog \u2197 \n Export to Mixpanel \u2197 \n \n \n \n \n \n \n API & Data Platform Overview \n Features Export from UI \n Export to Blob Storage \n Export for Fine-Tuning \n MCP Server \n Observations API \n Public API \n Query via SDKs \n \n \n \n \n \n \n Administration Auth \n Authentication & SSO \n Access Control (RBAC) \n SCIM and Org API \n Security \n Audit Logs \n Data Deletion \n Data Retention \n Security Docs \u2197 \n Configuration \n LLM Connections \n Spend Alerts \n Misc \n Billable Units \n Troubleshooting & FAQ \n \n \n \n Security & Guardrails \n More \n Roadmap \n Docs MCP Server \n SDK & API References API Reference \u2197 \n Python SDK \u2197 \n JS SDK \u2197 \n Java SDK \u2197 \n \n \n \n Security & Compliance \u2197 \n Support \u2197 \n \n \n \n Light \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Docs Observability Overview \n Copy page \n \n Observability & Tracing \n  Because AI is inherently non-deterministic, debugging your application without any observability tool is more like guesswork.\nWell implemented observability gives you the tools to understand what\u2019s happening inside your application and why. \n  The core of this is tracing. It gives you structured logs of every request: the exact prompt sent, the model\u2019s response, token usage, latency, and any tools or retrieval steps in between. \n  Langfuse captures all of this for you as you build. Here\u2019s an example of a trace in the Langfuse UI: \n  \n \n  \ud83c\udfa5 \n Watch this walkthrough of Langfuse Observability and how to integrate it with your application. \n \n \n  Getting started \n  Start by setting up your first trace . \n  Take a moment to understand the core concepts of tracing in Langfuse: traces, sessions, and observations . \n  Once you\u2019re up and running, you can start adding on more functionality to your traces. We recommend starting with the following: \n   Group traces into sessions for multi-turn applications \n  Split traces into environments for different stages of your application \n  Add attributes to your traces so you can filter them in the future \n   Already know what you want? Take a look under Features for guides on specific topics. \n \n Ask AI Get Started \n Was this page helpful? Yes No \n \n Support \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n",
  "title": "LLM Observability &amp; Application Tracing (open source) - Langfuse",
  "content_type": "text/html; charset=utf-8"
}