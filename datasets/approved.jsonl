{"item_type": "url", "content": "https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus", "note": "Context Engineering for AI Agents: Lessons from Building Manus - Discusses using filesystem as persistent context storage for AI agents, with detailed implementation insights on treating the file system as unlimited, persistent memory.", "category": "context-offloading", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents", "note": "Effective context engineering for AI agents - Covers Anthropic's approaches to context management including file-based memory tools and persistent context strategies for maintaining agent state across sessions.", "category": "context-offloading", "quality_score": 5.0}
{"item_type": "url", "content": "https://bentoml.com/llm/inference-optimization/prefix-caching", "note": "Prefix caching | LLM Inference Handbook - Comprehensive technical guide on prefix caching for LLM inference with specific focus on AI agents and RAG pipelines, explaining cache hit rate optimization.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.digitalocean.com/community/tutorials/prompt-caching-explained", "note": "Prompt Caching Explained - Detailed tutorial on prompt caching implementation with metrics like cache hit rate and practical examples for AI systems.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://redis.io/blog/prompt-caching-vs-semantic-caching", "note": "Prompt caching vs semantic caching: How to make AI agents faster - Explains prompt caching specifically for AI agents with focus on cost/latency optimization and prefix reuse strategies.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://sankalp.bearblog.dev/how-prompt-caching-works", "note": "How prompt caching works - Paged Attention and KV-cache reuse - Technical deep-dive into prompt caching mechanics with KV-cache reuse, explaining how to achieve consistent cache hits for better cost efficiency.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://google.github.io/adk-docs/agents/multi-agents", "note": "context-isolation", "category": "context-isolation", "quality_score": 5.0}
{"item_type": "url", "content": "https://docs.langchain.com/oss/python/langchain/multi-agent", "note": "context-isolation", "category": "context-isolation", "quality_score": 5.0}
{"item_type": "url", "content": "https://inkeep.com/blog/context-anxiety", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.anthropic.com/news/3-5-models-and-computer-use", "note": "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku - Launch announcement of Claude's computer use API that allows agents to perceive and interact with computer interfaces through cursor movement and typing.", "category": "computer-use", "quality_score": 5.0}
{"item_type": "url", "content": "https://aws.amazon.com/blogs/machine-learning/implement-human-in-the-loop-confirmation-with-amazon-bedrock-agents", "note": "Implement human-in-the-loop confirmation with Amazon Bedrock Agents - Demonstrates implementation of user confirmation and return-of-control patterns in Amazon Bedrock AI agents, showing how to build approval workflows for sensitive agent actions.", "category": "human-in-the-loop", "quality_score": 5.0}
{"item_type": "url", "content": "https://github.com/VectorInstitute/Agentic-Transparency", "note": "Transparency in Agentic AI: A Survey of Interpretability - Comprehensive GitHub repository surveying interpretability and explainability methods specifically for LLM-based agentic systems, directly addressing transparency challenges in agent reasoning.", "category": "transparency-patterns", "quality_score": 5.0}
{"item_type": "url", "content": "https://knightcolumbia.org/content/levels-of-autonomy-for-ai-agents-1", "note": "Levels of Autonomy for AI Agents - This framework defines five levels of escalating agent autonomy with user roles (operator, collaborator, consultant, approver, observer) and focuses on calibrating appropriate autonomy levels based on", "category": "autonomy-calibration", "quality_score": 5.0}
{"item_type": "url", "content": "https://aws.amazon.com/blogs/security/the-agentic-ai-security-scoping-matrix-a-framework-for-securing-autonomous-ai-systems", "note": "progressive-autonomy", "category": "progressive-autonomy", "quality_score": 5.0}
{"item_type": "url", "content": "https://gradientflow.substack.com/p/world-model-is-a-mess-heres-how-to", "note": "\"World Model\" is a mess. Here's how to make sense of it. - Technical analysis from an AI/ML-focused publication that clarifies different types of world models in AI systems and their architectural approaches for reasoning and planning.", "category": "world-models", "quality_score": 4.0}
{"item_type": "url", "content": "https://lilianweng.github.io/posts/2024-11-28-reward-hacking", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 5.0}
{"item_type": "url", "content": "https://www-cdn.anthropic.com/827afa7dd36e4afbb1a49c735bfbb2c69749756e/measuring-faithfulness-in-chain-of-thought-reasoning.pdf", "note": "Measuring Faithfulness in Chain-of-Thought Reasoning - This foundational Anthropic paper directly addresses CoT faithfulness by proposing tests to measure when chain-of-thought explanations are faithful versus post-hoc rationalizations in LLMs.", "category": "cot-faithfulness", "quality_score": 5.0}
