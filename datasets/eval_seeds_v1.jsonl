{"item_type": "url", "content": "https://www.flowhunt.io/blog/advanced-ai-agents-with-file-access-mastering-context-offloading-and-state-management", "note": "Advanced AI Agents with File Access: Mastering Context Offloading and State Management - This article directly addresses context offloading techniques where agents store large tool results in files rather than keeping them in context, exactly matching the category focus.", "category": "context-offloading", "quality_score": 4.0}
{"item_type": "url", "content": "https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus", "note": "Context Engineering for AI Agents: Lessons from Building Manus - Discusses using filesystem as persistent context storage for AI agents, with detailed implementation insights on treating the file system as unlimited, persistent memory.", "category": "context-offloading", "quality_score": 4.0}
{"item_type": "url", "content": "https://arxiv.org/html/2508.00031v1", "note": "Manage the Context of LLM-based Agents like Git - Academic paper introducing Git-Context-Controller for structured context management using persistent file systems with version control operations for long-horizon agent workflows.", "category": "context-offloading", "quality_score": 5.0}
{"item_type": "url", "content": "https://parallel.ai/articles/what-is-an-agent-harness", "note": "What is an agent harness? - Explains how agent harnesses implement memory systems including persistent context logs, summaries, and external knowledge stores to manage context beyond LLM limitations.", "category": "context-offloading", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents", "note": "Effective context engineering for AI agents - Covers Anthropic's approaches to context management including file-based memory tools and persistent context strategies for maintaining agent state across sessions.", "category": "context-offloading", "quality_score": 5.0}
{"item_type": "url", "content": "https://bentoml.com/llm/inference-optimization/prefix-caching", "note": "Prefix caching | LLM Inference Handbook - Comprehensive technical guide on prefix caching for LLM inference with specific focus on AI agents and RAG pipelines, explaining cache hit rate optimization.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.digitalocean.com/community/tutorials/prompt-caching-explained", "note": "Prompt Caching Explained - Detailed tutorial on prompt caching implementation with metrics like cache hit rate and practical examples for AI systems.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://github.com/pacoxu/AI-Infra/blob/main/docs/inference/caching.md", "note": "Caching in LLM Inference - pacoxu/AI-Infra - Technical documentation on GitHub covering prefix caching, KV cache optimization, and shared prefix caching for AI agent memory and inference.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://redis.io/blog/prompt-caching-vs-semantic-caching", "note": "Prompt caching vs semantic caching: How to make AI agents faster - Explains prompt caching specifically for AI agents with focus on cost/latency optimization and prefix reuse strategies.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://sankalp.bearblog.dev/how-prompt-caching-works", "note": "How prompt caching works - Paged Attention and KV-cache reuse - Technical deep-dive into prompt caching mechanics with KV-cache reuse, explaining how to achieve consistent cache hits for better cost efficiency.", "category": "context-caching", "quality_score": 4.0}
{"item_type": "url", "content": "https://google.github.io/adk-docs/agents/multi-agents", "note": "context-isolation", "category": "context-isolation", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2508.08322v1", "note": "context-isolation", "category": "context-isolation", "quality_score": 5.0}
{"item_type": "url", "content": "https://docs.langchain.com/oss/python/langchain/multi-agent", "note": "context-isolation", "category": "context-isolation", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.flowhunt.io/blog/context-engineering", "note": "context-isolation", "category": "context-isolation", "quality_score": 4.0}
{"item_type": "url", "content": "https://inkeep.com/blog/context-anxiety", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 4.0}
{"item_type": "url", "content": "https://newsletter.systemdesign.one/p/what-is-context-engineering", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 4.0}
{"item_type": "url", "content": "https://01.me/en/2025/12/context-engineering-from-claude", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.sundeepteki.org/blog/context-bench-a-benchmark-for-evaluating-agentic-context-engineering", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 5.0}
{"item_type": "url", "content": "https://mgx.dev/insights/token-efficient-agent-planning-foundational-concepts-advanced-techniques-and-future-directions/1d13cc92cab043b4b8049c73a9238739", "note": "progressive-disclosure", "category": "progressive-disclosure", "quality_score": 4.0}
{"item_type": "url", "content": "https://cseweb.ucsd.edu/~yuxiangw/classes/AIsafety-2025Fall/Lectures/Computer_Use_Agents.pdf", "note": "Computer Use Agents - The Architecture of Generalist AI for the Web - Academic paper defining Computer Use Agents (CUAs) as AI systems that interact with operating environments through shell commands, API calls, and desktop actions.", "category": "computer-use", "quality_score": 5.0}
{"item_type": "url", "content": "https://docs.aws.amazon.com/prescriptive-guidance/latest/agentic-ai-patterns/computer-use-agents.html", "note": "Computer-use agents - AWS Prescriptive Guidance - Technical architecture guide for building agents that control digital environments like browsers, terminals, and file systems using LLM reasoning.", "category": "computer-use", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.anthropic.com/news/developing-computer-use", "note": "Developing a computer use model - Official Anthropic blog explaining how Claude 3.5 was trained for computer use capabilities, interpreting screenshots and executing desktop actions.", "category": "computer-use", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.anthropic.com/news/3-5-models-and-computer-use", "note": "Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku - Launch announcement of Claude's computer use API that allows agents to perceive and interact with computer interfaces through cursor movement and typing.", "category": "computer-use", "quality_score": 5.0}
{"item_type": "url", "content": "https://inference.sh/blog/agent-runtime/human-in-the-loop", "note": "Human-in-the-Loop for AI Agents | blog - Provides comprehensive technical guide on implementing approval workflows in AI agent systems, covering state persistence, routing logic, and audit trails for human oversight.", "category": "human-in-the-loop", "quality_score": 4.0}
{"item_type": "url", "content": "https://developers.cloudflare.com/agents/concepts/human-in-the-loop", "note": "Human in the Loop \u00b7 Cloudflare Agents docs - Offers detailed documentation on human-in-the-loop workflows for AI agents, including best practices for long-term state persistence, error handling, and decision quality assessment.", "category": "human-in-the-loop", "quality_score": 4.0}
{"item_type": "url", "content": "https://zapier.com/blog/human-in-the-loop", "note": "Human-in-the-loop in AI workflows: Meaning and patterns - Explains practical patterns for adding human approval and verification checkpoints into AI agent workflows, with actionable examples of approval flows and stop hooks.", "category": "human-in-the-loop", "quality_score": 4.0}
{"item_type": "url", "content": "https://aws.amazon.com/blogs/machine-learning/implement-human-in-the-loop-confirmation-with-amazon-bedrock-agents", "note": "Implement human-in-the-loop confirmation with Amazon Bedrock Agents - Demonstrates implementation of user confirmation and return-of-control patterns in Amazon Bedrock AI agents, showing how to build approval workflows for sensitive agent actions.", "category": "human-in-the-loop", "quality_score": 5.0}
{"item_type": "url", "content": "https://developers.cloudflare.com/agents/guides/human-in-the-loop", "note": "Build a Human-in-the-loop Agent - Step-by-step technical guide for building AI agents with human approval mechanisms, covering tool approval flows, message streaming, and real-time confirmation patterns.", "category": "human-in-the-loop", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.emergentmind.com/topics/metacognitive-capabilities-in-llms", "note": "Metacognitive Capabilities in LLMs - Comprehensive overview of metacognitive abilities in LLMs including self-assessment, uncertainty estimation, and confidence calibration for improved AI agent performance.", "category": "metacognition", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2411.13537v2", "note": "Competence-Aware AI Agents with Metacognition for Unknown Situations and Environments - Academic paper presenting the MUSE framework that integrates self-assessment and self-regulation capabilities into LLM-based agents for handling novel scenarios.", "category": "metacognition", "quality_score": 5.0}
{"item_type": "url", "content": "https://pranavc28.github.io/blog/posts/thought-engineering-self-awareness", "note": "Using Natural Language Confidence From LLM Thought Engineering - Technical blog post exploring how LLMs can be engineered to recognize insufficient reasoning and assess their own confidence levels through natural language metacognition.", "category": "metacognition", "quality_score": 3.0}
{"item_type": "url", "content": "https://aclanthology.org/2025.findings-acl.1169.pdf", "note": "Metagent-P: Neuro-Symbolic Planning Agent with Metacognition - Academic paper describing a planning agent with metacognitive monitoring, evaluation, and regulation capabilities for improved decision-making in dynamic environments.", "category": "metacognition", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2508.06433v2", "note": "\ud835\udc40\u2062\ud835\udc52\u2062\ud835\udc5a^\ud835\udc5d: Exploring Agent Procedural Memory - Introduces Mem^p, a systematic framework for LLM agents to build, retrieve, and update procedural memory across long-horizon tasks, enabling agents to distill and reuse past experiences.", "category": "procedural-memory", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/abs/2512.18950", "note": "Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement - Presents MACLA framework that gives AI agents hierarchical procedural memory with Bayesian reliability tracking and contrastive refinement, achieving 78.1% performance while being 2,800x faster than p", "category": "procedural-memory", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/abs/2305.16291", "note": "Voyager: An Open-Ended Embodied Agent with Large Language Models - Introduces the seminal Voyager agent with an ever-growing skill library of executable code that serves as procedural memory, enabling compositional skill learning in Minecraft environments.", "category": "procedural-memory", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.llmwatch.com/p/ai-agents-of-the-week-papers-you-4b8", "note": "AI Agents of the Week: Papers You Should Know About - Comprehensive analysis of MACLA and other procedural memory frameworks, explaining how agents extract reusable procedures from trajectories and build hierarchical skill libraries for continual learnin", "category": "procedural-memory", "quality_score": 2.0}
{"item_type": "url", "content": "https://huggingface.co/blog/driaforall/mem-agent-blog", "note": "mem-agent: Equipping LLM Agents with Memory Using RL - Discusses procedural memory in AI agents including Voyager's skill library approach, comparing different memory architectures and their role in enabling continual skill acquisition and reuse.", "category": "procedural-memory", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2507.21504v1", "note": "Evaluation and Benchmarking of LLM Agents: A Survey - Comprehensive academic survey on LLM agent evaluation covering benchmarks, metrics, and evaluation frameworks specifically for AI agents.", "category": "agent-evaluation", "quality_score": 5.0}
{"item_type": "url", "content": "https://github.com/philschmid/ai-agent-benchmark-compendium", "note": "philschmid/ai-agent-benchmark-compendium - GitHub repository that compiles multiple AI agent benchmarks including SWE-Bench, AgentBench, and other evaluation frameworks for measuring agent capabilities.", "category": "agent-evaluation", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.evidentlyai.com/blog/ai-agent-benchmarks", "note": "10 AI agent benchmarks - Detailed overview of key agent evaluation benchmarks like AgentBench, WebArena, and ToolLLM for assessing multi-turn reasoning and tool use in AI agents.", "category": "agent-evaluation", "quality_score": 5.0}
{"item_type": "url", "content": "https://research.ibm.com/blog/AI-agent-benchmarks", "note": "The future of AI agent evaluation - IBM research perspective on agent evaluation evolution, covering planning benchmarks, tool calling assessment, and safety evaluation for LLM agents.", "category": "agent-evaluation", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.confident-ai.com/blog/llm-agent-evaluation-complete-guide", "note": "LLM Agent Evaluation: Tool Use, Task Completion, Reasoning - Comprehensive guide covering agent-specific evaluation metrics including tool-calling evaluation, workflow assessment, and reasoning evaluation for autonomous AI systems.", "category": "agent-evaluation", "quality_score": 5.0}
{"item_type": "url", "content": "https://arize.com/blog/llm-observability-for-ai-agents-and-applications", "note": "LLM Observability for AI Agents and Applications - Provides comprehensive coverage of tracing concepts for AI agents, explaining how traces and spans capture the complete journey through LLM workflows for debugging and optimization.", "category": "trace-driven-development", "quality_score": 5.0}
{"item_type": "url", "content": "https://dev.to/kuldeep_paul/a-practical-guide-to-distributed-tracing-for-ai-agents-1669", "note": "A Practical Guide to Distributed Tracing for AI Agents - Offers practical implementation guidance for trace-driven development in AI systems, covering OpenTelemetry patterns and tracing schema design specifically for AI agent workflows.", "category": "trace-driven-development", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.comet.com/site/blog/llm-tracing", "note": "LLM Tracing: The Foundation of Reliable AI Applications - Explains how structured LLM traces serve as documentation for AI workflows, providing end-to-end records that enable developers to understand and debug complex AI application behavior.", "category": "trace-driven-development", "quality_score": 5.0}
{"item_type": "url", "content": "https://datasciencedojo.com/blog/llm-evaluation-with-langsmith", "note": "Evaluate and trace with LangSmith to Master LLM Optimization - Demonstrates how LangSmith tracing provides detailed documentation of agent reasoning chains, showing how traces become essential documentation for understanding AI agent decision-making processes.", "category": "trace-driven-development", "quality_score": 4.0}
{"item_type": "url", "content": "https://github.com/VectorInstitute/Agentic-Transparency", "note": "Transparency in Agentic AI: A Survey of Interpretability - Comprehensive GitHub repository surveying interpretability and explainability methods specifically for LLM-based agentic systems, directly addressing transparency challenges in agent reasoning.", "category": "transparency-patterns", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2511.07083v1", "note": "Increasing AI Explainability by LLM Driven Standard - Academic paper proposing LLM-driven standard processes that create transparent, auditable decision traces by embedding reasoning within explainable frameworks.", "category": "transparency-patterns", "quality_score": 5.0}
{"item_type": "url", "content": "https://docs.aws.amazon.com/bedrock/latest/userguide/trace-events.html", "note": "Track agent's step-by-step reasoning process using trace - AWS documentation on agent tracing that provides detailed information about tracking an agent's reasoning path and decision-making process for troubleshooting and transparency.", "category": "transparency-patterns", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.salesforce.com/agentforce/ai-agents/react-agents", "note": "What is AI Reasoning? A Guide to Logical AI Systems - Guide explaining the ReAct framework's Thought-Action-Observation cycle that makes agent reasoning visible through explicit internal monologue and decision tracing.", "category": "transparency-patterns", "quality_score": 2.0}
{"item_type": "url", "content": "https://www.fiddler.ai/blog/anatomy-ai-agent", "note": "Anatomy of an Agent: Observing the Full Lifecycle - Blog post from AI observability company detailing how to capture agent internal reasoning, belief states, and decision processes for transparent agent behavior monitoring.", "category": "transparency-patterns", "quality_score": 4.0}
{"item_type": "url", "content": "https://knightcolumbia.org/content/levels-of-autonomy-for-ai-agents-1", "note": "Levels of Autonomy for AI Agents - This framework defines five levels of escalating agent autonomy with user roles (operator, collaborator, consultant, approver, observer) and focuses on calibrating appropriate autonomy levels based on", "category": "autonomy-calibration", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2410.12361v3", "note": "Shifting LLM Agents from Reactive Responses to Active Assistance - Introduces ProactiveBench dataset and methods for calibrating LLM agent proactiveness, including reward models that simulate human judgment to automatically evaluate and control the proactive behavior", "category": "autonomy-calibration", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2509.22735v1", "note": "Regulating the Agency of LLM-based Agents - Presents white-box activation-level control methods for calibrating agent autonomy with granular, continuous adjustment capabilities, allowing precise calibration of agent behavior to match organizati", "category": "autonomy-calibration", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2506.12469v1", "note": "Levels of Autonomy for AI Agents Working Paper - Academic working paper detailing the theoretical framework for agent autonomy levels and how developers can make informed calibrations of agent autonomy based on target use cases and desired user expe", "category": "autonomy-calibration", "quality_score": 5.0}
{"item_type": "url", "content": "https://stytch.com/blog/handling-ai-agent-permissions", "note": "Handling AI agent permissions - Stytch - Technical guide focused on permission settings and authorization models for controlling AI agent behavior, addressing unpredictable autonomy through proper permission scoping and user confirmation mec", "category": "autonomy-calibration", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.elixirdata.co/blog/progressive-autonomy", "note": "progressive-autonomy", "category": "progressive-autonomy", "quality_score": 4.0}
{"item_type": "url", "content": "https://aws.amazon.com/blogs/security/the-agentic-ai-security-scoping-matrix-a-framework-for-securing-autonomous-ai-systems", "note": "progressive-autonomy", "category": "progressive-autonomy", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.llmwatch.com/p/guided-autonomy-progressive-trust", "note": "progressive-autonomy", "category": "progressive-autonomy", "quality_score": 4.0}
{"item_type": "url", "content": "https://gradientflow.substack.com/p/agentic-ai-applications-a-field-guide", "note": "progressive-autonomy", "category": "progressive-autonomy", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.gocodeo.com/post/error-recovery-and-fallback-strategies-in-ai-agent-development", "note": "Error Recovery and Fallback Strategies in AI Agent Development - Comprehensive guide on structured fallback strategies, graceful degradation patterns, and human escalation mechanisms specifically for LLM-based AI agents.", "category": "error-recovery-ux", "quality_score": 4.0}
{"item_type": "url", "content": "https://deanm.ai/blog/architectural-paradigms-for-scalable-unstructured-data-processing-in-enterprise-z4bfj-s7raj-6w56c-rkra7", "note": "Multi-Agent Systems with Rollback Mechanisms - Dean Mai - Details saga-based coordination and rollback mechanisms tailored for LLM-powered agents, including constraint-sensitive recovery and intelligent backtracking.", "category": "error-recovery-ux", "quality_score": 1.0}
{"item_type": "url", "content": "https://research.ibm.com/blog/undo-agent-for-cloud", "note": "An 'undo-and-retry' mechanism for agents - Presents IBM's STRATUS system with transactional-no-regression (TNR) approach for safe rollback strategies in AI agent systems to prevent catastrophic actions.", "category": "error-recovery-ux", "quality_score": 5.0}
{"item_type": "url", "content": "https://aclanthology.org/2025.emnlp-main.892.pdf", "note": "Generator-Assistant Stepwise Rollback Framework for LLM Agents - Academic paper describing GA-Rollback framework that enables LLM agents to detect errors and roll back to previous trajectory points for better decision-making.", "category": "error-recovery-ux", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.newline.co/@zaoyang/5-recovery-strategies-for-multi-agent-llm-failures--673fe4c4", "note": "5 Recovery Strategies for Multi-Agent LLM Failures - Practical guide covering state persistence, checkpointing, and redundancy strategies specifically designed for multi-agent LLM system failure recovery.", "category": "error-recovery-ux", "quality_score": 4.0}
{"item_type": "url", "content": "https://arxiv.org/abs/2411.08027", "note": "LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models - Demonstrates how LLMs can be combined with physics engines to create world models that perform complex physical reasoning tasks, directly addressing physics-aware reasoning in AI agents.", "category": "world-models", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.dexterity.ai/blog/transactable-world-models", "note": "Transactable World Models - Describes a production-level world model architecture for physical AI that enables real-time physics reasoning with interpretability guarantees for robotic agents.", "category": "world-models", "quality_score": 4.0}
{"item_type": "url", "content": "https://worldmodels.github.io", "note": "World Models - The seminal research work that established world models as environments for training AI agents, showing how to build complete RL environments using learned world models.", "category": "world-models", "quality_score": 5.0}
{"item_type": "url", "content": "https://github.com/knightnemo/Awesome-World-Models", "note": "Awesome World Models - A Curated List of Amazing Works in World Modeling - Comprehensive GitHub repository specifically focused on world models for AI agents across embodied AI, autonomous driving, and NLP applications with clear focus on AI systems.", "category": "world-models", "quality_score": 5.0}
{"item_type": "url", "content": "https://gradientflow.substack.com/p/world-model-is-a-mess-heres-how-to", "note": "\"World Model\" is a mess. Here's how to make sense of it. - Technical analysis from an AI/ML-focused publication that clarifies different types of world models in AI systems and their architectural approaches for reasoning and planning.", "category": "world-models", "quality_score": 4.0}
{"item_type": "url", "content": "https://belovedpizza.substack.com/p/gaming-the-system-reward-hacking", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.emergentmind.com/topics/reward-hacking-in-rlvr", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 5.0}
{"item_type": "url", "content": "https://lilianweng.github.io/posts/2024-11-28-reward-hacking", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 5.0}
{"item_type": "url", "content": "https://aisafety.info/questions/8SIU/What-is-reward-hacking", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 4.0}
{"item_type": "url", "content": "https://www.lesswrong.com/posts/mMBoPnFrFqQJKzDsZ/ai-safety-101-reward-misspecification", "note": "reward-hacking", "category": "reward-hacking", "quality_score": 5.0}
{"item_type": "url", "content": "https://www-cdn.anthropic.com/827afa7dd36e4afbb1a49c735bfbb2c69749756e/measuring-faithfulness-in-chain-of-thought-reasoning.pdf", "note": "Measuring Faithfulness in Chain-of-Thought Reasoning - This foundational Anthropic paper directly addresses CoT faithfulness by proposing tests to measure when chain-of-thought explanations are faithful versus post-hoc rationalizations in LLMs.", "category": "cot-faithfulness", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2601.02314v1", "note": "A Structural Causal Framework for Auditing Faithfulness in Chain-of-Thought Reasoning - Introduces Project Ariadne, a novel XAI framework using Structural Causal Models to audit the causal integrity of LLM agent reasoning and detect unfaithful CoT explanations.", "category": "cot-faithfulness", "quality_score": 5.0}
{"item_type": "url", "content": "https://aigi.ox.ac.uk/wp-content/uploads/2025/07/Cot_Is_Not_Explainability.pdf", "note": "Chain-of-Thought Is Not Explainability - Proposes a rigorous framework for evaluating CoT faithfulness based on procedural soundness, causal relevance, and completeness, with automated audit pipeline for interpretability claims.", "category": "cot-faithfulness", "quality_score": 5.0}
{"item_type": "url", "content": "https://arxiv.org/html/2405.18915v1", "note": "Large Language Models are Bridging Reasoners - Studies CoT faithfulness at the granularity of individual reasoning steps, identifying centralized vs distributed reasoning paradigms and their relationship to faithfulness in LLMs.", "category": "cot-faithfulness", "quality_score": 5.0}
{"item_type": "url", "content": "https://www.anthropic.com/research/tracing-thoughts-language-model", "note": "Tracing the thoughts of a large language model - Explores interpretability techniques to distinguish \"faithful\" from \"unfaithful\" reasoning in Claude's chain-of-thought explanations, showing how models sometimes engage in convincing but false reason", "category": "cot-faithfulness", "quality_score": 5.0}
